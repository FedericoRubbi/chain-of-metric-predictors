\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\geometry{a4paper, margin=1in}

\title{Comparison of Greedy MLP and Vanilla MLP Architectures}
\author{}
\date{}

\begin{document}
\maketitle

\section{Introduction}
Here is a comparative study of two architectures for supervised classification: the standard feed-forward Multi-Layer Perceptron (MLP), and a novel \emph{Greedy MLP} trained with an amended cross-entropy (ACE) objective. Both are evaluated on canonical datasets such as MNIST, CIFAR-10, and CIFAR-100. The goal of this comparison is to highlight structural, algorithmic, and optimization differences, and to assess the interpretability and computational properties of each model.

\section{Vanilla MLP}
The vanilla MLP serves as the classical baseline. Given an input $x \in \mathbb{R}^d$, the hidden activations are computed recursively as
\[
  h_i = \sigma(W_i h_{i-1} + b_i), \qquad h_0 = x,
\]
where $W_i \in \mathbb{R}^{N \times N}$ are weight matrices, $b_i$ are biases, and $\sigma$ is the ReLU nonlinearity. A final linear layer maps $h_L$ to class logits in $\mathbb{R}^C$:
\[
  f(x) = W_{L+1} h_L + b_{L+1}.
\]
Training follows the standard cross-entropy objective,
\[
  \mathcal{L}_{\text{MLP}} = - \frac{1}{B} \sum_{n=1}^B \sum_{c=1}^C y_{n,c} \log \big( \mathrm{softmax}(f(x_n))_c \big),
\]
with one-hot targets $y_{n,c}$. In this classical formulation, predictions are only available at the output layer, and optimization proceeds end-to-end through backpropagation with a single optimizer.

\section{Greedy MLP}
The Greedy MLP departs significantly from the standard formulation. Each layer is still defined as $h_i = \sigma(W_i h_{i-1} + b_i)$ with fixed width $N$, but instead of relying on a classification head, the model introduces a set of fixed class anchors $E = \{e_c \in \mathbb{R}^N\}_{c=1}^C$. At each layer, activations are directly compared to these anchors to produce similarity scores. These can be defined either as cosine similarity,
\[
  G_i(x,c) = \frac{h_i^\top e_c}{\|h_i\| \, \|e_c\|},
\]
or as negative squared Euclidean distance,
\[
  G_i(x,c) = - \|h_i - e_c\|^2.
\]

Layerwise class probabilities are then obtained by applying a temperature-scaled softmax,
\[
  q_i(c|x) = \frac{\exp(G_i(x,c)/\tau)}{\sum_{c'} \exp(G_i(x,c')/\tau)}.
\]
Each layer is supervised with a local objective consisting of a classification term and an amended cross-entropy regularizer:
\[
  \mathcal{L}_i = H(p, q_i) - \lambda H(q_i, q_{i+1}),
\]
where $p(c|x)=1$ is the density of the ground-truth class $c$ given the sample $x$, and $H(\cdot,\cdot)$ denotes cross-entropy. The second term encourages diversity between consecutive layers by penalizing overly similar distributions. For the last layer, the regularizer vanishes since $q_{L+1}$ is undefined.

Training follows a strictly greedy procedure. Each layer maintains its own optimizer (Adam in the experiments). During a training step, the batch is propagated to layer $i$, the local loss $\mathcal{L}_i$ is computed, and gradients are applied only to the parameters of that layer. Inputs from previous layers are detached, ensuring independence of updates. This yields a \emph{layer-wise greedy optimization scheme} rather than full backpropagation.

\section{Comparison}
From an architectural perspective, the vanilla MLP follows the conventional pipeline of stacked linear+ReLU blocks culminating in a classification head, while the Greedy MLP replaces the head with anchor-based predictions available at every layer. This allows monitoring of intermediate representations in terms of classification accuracy.

Prediction mechanisms also differ: in the vanilla model, probabilities are obtained only at the final layer, whereas the greedy model produces a distribution $q_i$ at each layer, enabling analysis of per-layer performance.

Training procedures diverge strongly. The vanilla MLP uses a single optimizer and backpropagation across all layers, while the greedy model uses per-layer optimizers with detached activations, performing localized updates. Loss formulations also reflect this contrast: the vanilla loss is a single global cross-entropy, whereas the greedy model employs a sequence of local losses augmented with ACE regularization:
\[
  \mathcal{L}_{\text{MLP}} = H(p, q^{\text{MLP}}), \qquad
  \mathcal{L}_i^{\text{Greedy}} = H(p, q_i) - \lambda H(q_i, q_{i+1}).
\]

Additional hyperparameters appear in the greedy formulation, notably the temperature $\tau$, the ACE weight $\lambda$, and the choice of similarity metric. These provide more flexibility but also introduce additional complexity in tuning.

\section{Evaluation}
Evaluation of the vanilla model focuses on final test accuracy. By contrast, the greedy model naturally yields per-layer accuracies $\{\mathrm{acc}_i\}_{i=1}^L$ in addition to the final-layer performance. This feature not only provides interpretability of intermediate representations but also allows the study of information flow and representation quality across depth.

\section{Conclusion}
In summary, the vanilla MLP represents the classical approach to supervised classification, with a single global loss and end-to-end optimization. The Greedy MLP introduces anchor-based classification, per-layer probabilistic outputs, and greedy optimization with amended cross-entropy regularization. These changes enable interpretable intermediate predictions and encourage diversity across layers, at the cost of added training complexity and hyperparameters. The comparative analysis illustrates how architectural and algorithmic choices influence both performance and representation learning dynamics.

\end{document}